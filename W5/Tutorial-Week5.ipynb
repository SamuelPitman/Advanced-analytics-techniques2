{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f76d664-d35b-452d-8faa-0ce85012aa29",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Week 5 Tutorial Problems {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d7623e-e76f-47c3-875a-d53b45f487a4",
   "metadata": {},
   "source": [
    "1. Revise some of the commonly used Pandas functions.\n",
    "\n",
    "2. Complete the following Kaggle Mini Tutorials \n",
    "- If we run out of time to be completed in self-study time\n",
    "    - Lists: [https://www.kaggle.com/colinmorris/lists](https://www.kaggle.com/colinmorris/lists)   \n",
    "    - Loops and List Comprehensions: [https://www.kaggle.com/colinmorris/loops-and-list-comprehensions](https://www.kaggle.com/colinmorris/loops-and-list-comprehensions)   \n",
    "    - Pandas Indexing, Selecting & Assigning: [https://www.kaggle.com/residentmario/indexing-selecting-assigning](https://www.kaggle.com/residentmario/indexing-selecting-assigning)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d189c50-869b-42b8-8242-ddc8dcda592d",
   "metadata": {},
   "source": [
    "---\n",
    "**Outline**\n",
    "In this tutorial we will revise several frequently used Pandas Functions.\n",
    "\n",
    "- `unique()` Return unique values from a DataFrame. https://pandas.pydata.org/docs/reference/api/pandas.unique.html\n",
    "- `nunique()` Count the number of distinct elements in specified axis. https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.nunique.html\n",
    "- `drop_duplicates()` Return DataFrame with duplicate rows removed. https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop_duplicates.html\n",
    "- `value_counts()` Return a Series containing counts of unique values. https://pandas.pydata.org/docs/reference/api/pandas.Series.value_counts.html\n",
    "- `merge()` Merge DataFrame or named Series objects with a database-style join. https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html\n",
    "- `concat()` Concatenate pandas objects along a particular axis. https://pandas.pydata.org/docs/reference/api/pandas.concat.html\n",
    "- `loc[]` with multiple conditions inside. https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.loc.html\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4bbc14-ec15-4b4d-b84d-d06260256127",
   "metadata": {},
   "source": [
    "- Import Libraries\n",
    "\n",
    "```\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "```\n",
    "\n",
    "- Create a dataset to be used in the tutorial\n",
    "\n",
    "```\n",
    "# create the dataframe used\n",
    "df = pd.DataFrame({\n",
    "    'StudentID': ['S001', 'S002', 'S003', 'S004', 'S005', 'S006', 'S007', 'S008', 'S009'],\n",
    "    'StudentName': ['Angela', 'Frank', 'Grace', 'Jack', 'Bernadette', 'Alexander', 'Fiona', 'Colin', 'Tom'],\n",
    "    'Postcode': ['1234', '1234', '2000', np.nan, '2001', np.nan, '2020','2020', '2122'], \n",
    "    'CourseCode': ['ACCG001','ACCG001','INFO300','INFO200', 'INFO200', \n",
    "                   'BUSA001','BUSA001','AFIN003','ACCG001']})\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8901e83-f849-4768-bc16-98c29648caf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a813b853-6687-4f2b-bebc-308797764075",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dffd64c-a4ac-4dca-a1b6-22b18aae6768",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "994acf53-f37a-4106-b64f-87d8c4f4a2b2",
   "metadata": {},
   "source": [
    "--- \n",
    "### `unique()`\n",
    "\n",
    "- Returns unique values.\n",
    "- Uniques are returned in the order of appearance. This does NOT sort.\n",
    "- Significantly faster than numpy.unique for long enough sequences.\n",
    "- Will also include `None` (missing values) as a unique element.\n",
    "\n",
    "Examples\n",
    "- If we are insterested in what are all the unique values for the feature **CourseCode**, we could use `unique()` function.\n",
    "\n",
    "```\n",
    "df['CourseCode'].unique()\n",
    "\n",
    "df['Postcode'].unique()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41dbc005-64d8-4b5b-ae0f-b89965d910f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c8d5af-db12-462f-a5f1-5d917f8077a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e794024e-ea15-4411-9f00-6cdfb9d7c241",
   "metadata": {},
   "source": [
    "--- \n",
    "### `nunique()`\n",
    "\n",
    "- Count number of distinct elements in specified axis.\n",
    "- Return Series with number of distinct elements. \n",
    "- Option `dropna = False` will count missing values as a unique element\n",
    "\n",
    "There are two main difference between `unique()` and `nunique()`:\n",
    "- `unique()` gives the unique value, whereas `nunique()` give the number of unique value.\n",
    "- `unique()` includes **NA** value, whereas `nunique()` does not take **NA** value into account by default (but see dropna option)\n",
    "\n",
    "We will illustrate it by applying `nunique()` on the feature **Postcode**.\n",
    "\n",
    "Note: \n",
    "- To check the NA value, we could use `isnull()`. \n",
    "- To check the number of NA value, we could use `isnull().sum()`.\n",
    "\n",
    "```\n",
    "print(df['Postcode'].isnull())\n",
    "\n",
    "print(f'There are {df[\"Postcode\"].isnull().sum()} NA values in the column Postcode.')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76138975-336b-438e-b0a7-b0080f6b10e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e4c0d5-d002-4aaf-a052-6bcc45534218",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "227f3fcb-6b7e-4138-92b3-7dba0082771d",
   "metadata": {},
   "source": [
    "- We can now compute the number of unique values as follows:\n",
    "\n",
    "```\n",
    "print(f'Unique values in Postcode are {df[\"Postcode\"].unique()}')\n",
    "\n",
    "print(f'Number of unique values in Postcode which includes NA value is {df[\"Postcode\"].nunique()}')\n",
    "\n",
    "print(f'Number of unique values in Postcode which includes NA value is {df[\"Postcode\"].nunique(dropna=False)}')\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56e3a46-b149-4a56-93bb-0889c037485b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb579e22-ef75-44a1-9667-d83da1acfe47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58b0ebd-588c-41d7-bd0b-01b9cd56b5ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b90d5e3b-fbe0-49ff-9c91-5e5f345b400b",
   "metadata": {},
   "source": [
    "---\n",
    "### `drop_duplicates()`\n",
    "\n",
    "- Returns DataFrame with duplicate rows removed\n",
    "- Considering certain columns is optional\n",
    "- To remove duplicates on specific column(s), use `subset`\n",
    "- Must use `inplace = True` to modify the original dataframe\n",
    "- keep{‘first’, ‘last’, False}, default ‘first’. Determines which duplicates (if any) to keep.\n",
    "    - first : Drop duplicates except for the first occurrence (default value)\n",
    "    - last : Drop duplicates except for the last occurrence.\n",
    "    - False : Drop all duplicates.\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "# create dataframes\n",
    "df = pd.DataFrame({\n",
    "    'productID':[\"p01\",\"p02\",\"p03\",\"p04\",\"p01\",\"p02\",\"p05\"],\n",
    "    'Price':[100,250,220,300,100,250,300],\n",
    "    'productType':['A','A','B','C','A','A','B']\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "df.drop_duplicates()\n",
    "\n",
    "\n",
    "df.drop_duplicates(subset='productType')\n",
    "\n",
    "df\n",
    "\n",
    "df.drop_duplicates(subset='productType', inplace = True)\n",
    "df\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07064b30-a90c-42c0-a307-ec00dd600de8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7da9d4-246c-453a-83cb-56addf8ec8c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd3b60b-62db-4ad8-9261-69c6dc5a96d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b24af51-da8c-4d6b-a2e5-8ef20ec65406",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d71c6047-259c-4be0-bff4-a075189d7d2d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### `value_counts()`\n",
    "\n",
    "- Returns a Series containing `counts` of unique values\n",
    "- The resulting object will be in descending order so that the first element is the most frequently-occurring element. \n",
    "- Excludes NA values by default.\n",
    "\n",
    "```\n",
    "df['CourseCode'].value_counts()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c834992c-c4ae-48b0-acff-dd0150ee1b99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c538964a-a39a-4bd3-a8d2-347c243a3050",
   "metadata": {},
   "source": [
    "- `value_counts()` is also useful when we would like to do some data visualization;\n",
    "- `value_counts()` could be used to create bar plot, which shows the frequence of each class;\n",
    "    - There are also many other ways of doing this \n",
    "\n",
    "```\n",
    "# course_freq stores course name and corresponding frequnce\n",
    "course_freq = df['CourseCode'].value_counts()\n",
    "\n",
    "# use course_freq to generate a bar plot\n",
    "ax = course_freq.plot.barh(title='Bar Plot - Enrolment in differnt courses')\n",
    "ax.set_xlabel('Frequency')\n",
    "ax.set_ylabel('Course')\n",
    "plt.show()\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d55d46-bf01-47fd-ad31-dd33dee6bdc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "32e0200d-ab07-43b7-8b22-9579b56f18b3",
   "metadata": {},
   "source": [
    "---\n",
    "### `merge()`\n",
    "\n",
    "- Merge DataFrame or named Series objects with a **database-style join**.\n",
    "- A named Series object is treated as a DataFrame with a single named column.\n",
    "- The join is done on columns or indexes. \n",
    "    - If joining columns on columns, the DataFrame indexes will be ignored. \n",
    "    - Otherwise if joining indexes on indexes or indexes on a column or columns, the index will be passed on. \n",
    "    - When performing a cross merge, no column specifications to merge on are allowed.\n",
    "    \n",
    "- Create two new DataFrames\n",
    "\n",
    "```\n",
    "product = pd.DataFrame({\n",
    "    'productID':[\"p01\",\"p02\",\"p03\",\"p04\",\"p05\",\"p06\"],\n",
    "    'productName':[\"ABCD\",\"EFGH\",\"IJKL\",\"MNOP\", \"QRST\", \"UVWX\"],\n",
    "    'Price' :[100,250,220,300,190,900]\n",
    "})\n",
    "print(product)\n",
    "\n",
    "discount = pd.DataFrame({\n",
    "    'discountID':[\"d01\",\"d02\",\"d03\",\"d04\",\"d05\",\"d06\"],\n",
    "    'productID':[\"p04\",\"p03\",\"p01\",\"p02\",\"p09\",\"p10\"],\n",
    "    'Discount':[\"20%\",\"30%\",\"40%\",\"20%\",\"25%\",\"30%\"]\n",
    "})\n",
    "print(discount)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45db4976-09fc-4972-ba94-d4da0b2bea77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e65ada20-5726-4ddd-a74a-f82070e2147e",
   "metadata": {},
   "source": [
    "\n",
    "### parameter `on`:\n",
    "\n",
    "- Column or index level names to join on. \n",
    "- These must be found in both DataFrames. \n",
    "- If on is None and not merging on indexes then this defaults to **the intersection of the columns** (columnns that have the same name) in both DataFrames. default`None`\n",
    "\n",
    "\n",
    "### parameter `how`:\n",
    "\n",
    "- Type of merge to be performed.\n",
    "- how{`‘left’`, `‘right’`, `‘outer’`, `‘inner’`, `‘cross’`}, default `‘inner’`\n",
    "- `inner`: use intersection of keys from both frames, similar to a SQL inner join; preserve the order of the left keys.\n",
    "- `left`: use only keys from left frame, similar to a SQL left outer join; preserve key order.\n",
    "- `right`: use only keys from right frame, similar to a SQL right outer join; preserve key order.\n",
    "- `outer`: use union of keys from both frames, similar to a SQL full outer join; sort keys lexicographically.\n",
    "- `cross`: creates the cartesian product from both frames, preserves the order of the left keys.\n",
    "\n",
    "\n",
    "The most frequently-used join types are: `inner`, `left`, and `right`.\n",
    "\n",
    "```\n",
    "# Merge DataFrames by Columns\n",
    "pd.merge(product, discount, on = 'productID', how = 'inner')\n",
    "\n",
    "pd.merge(product, discount, on = 'productID', how = 'left')\n",
    "\n",
    "pd.merge(product, discount, on = 'productID', how = 'right')\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4da4e5-1f48-460c-8237-0b8af80afc82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ee8a40-c02f-4a69-8063-f87bf5719182",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e7d559-9dbb-42c8-a18f-56e6cdb9ace5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71e2dd69-9aa6-449e-8c4b-9d8a6f7636e2",
   "metadata": {},
   "source": [
    "---\n",
    "### `concat()`\n",
    "\n",
    "- Another function that concatenates (joins) pandas objects along a particular axis.\n",
    "    - `axis = 0` combine vertically\n",
    "    - `axis = 1` combine horizontally\n",
    "\n",
    "- Difference between `merge()` and `concat()`\n",
    "    - `merge()` for combining data on **common** columns or indices.\n",
    "    - `concat()` for combining DataFrames horizontally or vertically.\n",
    "    \n",
    "    \n",
    "\n",
    "- Create dataframes\n",
    "\n",
    "```\n",
    "df1 = pd.DataFrame({\n",
    "    'productID':[\"p01\",\"p02\",\"p03\",\"p04\",\"p05\",\"p06\"],\n",
    "    'productName':[\"ABCD\",\"EFGH\",\"IJKL\",\"MNOP\", \"QRST\", \"UVWX\"],\n",
    "    'Price' :[100,250,220,300,190,900]\n",
    "})\n",
    "\n",
    "df2 = pd.DataFrame({\n",
    "    'productID':[\"p07\",\"p08\",\"p09\",\"p10\"],\n",
    "    'productName':[\"DJFJ\",\"DFKD\",\"FKKM\",\"OEKL\"],\n",
    "    'Price' :[190,490,920,310]\n",
    "})\n",
    "\n",
    "df3 = pd.DataFrame({\n",
    "    'productType':[\"A\",\"B\",\"C\",\"D\"],\n",
    "    'releasedYear':[2020,2012,2011,2009]\n",
    "})\n",
    "```\n",
    "\n",
    "- Combine data vertically\n",
    "```\n",
    "pd.concat([df1, df2], axis = 0)\n",
    "```\n",
    "\n",
    "- Combine data horizontally\n",
    "```\n",
    "pd.concat([df2, df3], axis = 1)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efa53e6-2649-43cf-8475-85906dca8de5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da383e39-5676-4326-9784-ed8153c79deb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ec0369-299a-4201-8557-4e1e5763c187",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55080025-b965-443a-851b-450f1b066e33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7361d70f-10eb-42f5-90f8-d6af13c9022b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39700dbb-a6da-405d-bc3a-ec09d9c4d1e2",
   "metadata": {},
   "source": [
    "---\n",
    "## `loc[]` with multiple conditions inside\n",
    "\n",
    "- Access a group of rows and columns by labels\n",
    "- By using `loc[]` you can apply multiple conditions. \n",
    "    - Make sure you **surround each condition with round brackets**. Not using this will get you incorrect results.\n",
    "    \n",
    "    \n",
    "```\n",
    "# create dataframes\n",
    "df = pd.DataFrame({\n",
    "    'productID':[\"p01\",\"p02\",\"p03\",\"p04\",\"p05\",\"p06\",\"p07\",\"p08\",\"p09\",\"p10\"],\n",
    "    'Price':[100,250,220,300,190,900,1050,40,30,90],\n",
    "    'productType':['A','A','B','C','B','A','A','B','A','C'],\n",
    "    'yearReleased':[2010,2012,2020,2013,2020,2021,2014,2009,2020,2022],\n",
    "    'cumulativeSales($)':[100000,200000,190000,90000,10000,\n",
    "                          140000,10000,6000,9000,300000]\n",
    "})\n",
    "\n",
    "df\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec83124-5a13-4ad5-acc5-5af1b2431b7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ee7383d-dcb9-468b-abaa-495c00c6d88f",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "Select products that price is greater than $100 and released before 2020.\n",
    "\n",
    "```\n",
    "df.loc[(df['Price']>100) & (df['yearReleased']<2020)] # '&' refers to 'and'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18a4707-17d0-442d-8de7-b5540f1d1925",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93edf48c-6653-414a-a027-2fa1fac9f5ed",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "Select products that price is less than $ 100, product type is B, and released before 2020.\n",
    "\n",
    "```\n",
    "df.loc[(df['Price']<100) & (df['productType']=='B') & (df['yearReleased']<2020)]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9598a4-46ea-499e-b4d5-33b9e59eaeab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7a35391-b642-4536-b81b-3c37aa1cb12d",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "Select products that either price is less than 100 `or` cumulative sales is less than 100000.\n",
    "\n",
    "```\n",
    "df.loc[(df['Price']<100) | (df['cumulativeSales($)']<100000)]\n",
    "# '|' refers to 'or'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef74f9eb-b767-4585-8992-723432ca3c0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76e0825-085b-432d-bff7-ff9324f740f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c858cf39-9d51-4af0-9dc6-5122e15d902e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7982086b-ca9d-4a81-943a-94f78db3b01a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
