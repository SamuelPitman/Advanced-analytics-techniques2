{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 5 Lecture and Computer Lab - Data Preprocessing: Building Good Training Datasets {-}\n",
    "\n",
    "## Unit Convenor & Lecturer {-}\n",
    "\n",
    "George Milunovich  \n",
    "george.milunovich@mq.edu.au\n",
    "\n",
    "## References {-}\n",
    "1. Python Machine Learning 3rd Edition by Raschka & Mirjalili - Chapter 4\n",
    "2. Various open-source material\n",
    "\n",
    "## Learning Objectives {-}\n",
    "\n",
    "- Removing and Imputing Missing Values from the Dataset\n",
    "- Getting Categorical Data into Shape for Use with Machine Learning Algorithms\n",
    "- Selecting Relevant Features for Model Construction\n",
    "- Feature Importance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "--- \n",
    "\n",
    "# Removing and Imputing Missing Values from the Dataset {-}\n",
    "\n",
    "If the data is inaccurate, missing or irrelevant we will not be able to produce good predictions (no matter how good and sophisticated our forecasting algorithms is)\n",
    "- **Quality** and **amount of useful information** are key determinants of how well a machine learning algorithm can learn\n",
    "- We must examine and preprocess data before we use it to train a machine learning model\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with Missing Data {-}\n",
    "\n",
    "- Data is often missing\n",
    "    - Errors in data collection \n",
    "    - Certain data doesn't exist \n",
    "    - Surveys are incorrectly answered, e.g. income often understated\n",
    "    - Etc\n",
    "\n",
    "\n",
    "One of the main problems is **missing observations**. How Python deals with missing observations:  \n",
    "- Common placeholders for missing observations in databases `NaN` - 'not a number' or `NULL`\n",
    "- If we try to train an algorithm using such dataframes we will often get an error\n",
    "- `scikit-learn` was originally developed to work with `NumPy` arrays\n",
    "    - Clean data in `pandas` and then export into `numpy` using `df.values`\n",
    "    - Newer versions of some `scikit-learn` libraries also work with `pandas` dataframes\n",
    "\n",
    "<hr style=\"width:25%;margin-left:0;\">   \n",
    "\n",
    "### Identifying Missing Values in Tabular Data {-}\n",
    "\n",
    "- When dealing with missing data it is easiest to use `pandas`\n",
    "    - `isnull` method returns a `DataFrame` with Boolean values to indicate whether a cell contains a numeric value (`False`) or if data is missing (`True`)\n",
    "    - we can also `.sum()` after `isnull` which treats False = 0, and True = 1 -> get a number of missing values for each column or row\n",
    "    - `pandas` method `.info()` also provides a count of Non-Null Values for each colum\n",
    "    \n",
    "- Lets create some missing data in a `pandas` DataFrame\n",
    "\n",
    "```\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from io import StringIO # allows us to read from a string as if we are reading from a file\n",
    "\n",
    "csv_data = 'A, B, C, D \\n 1.0, 2.0, 3.0, 4.0 \\n 5.0, 6.0,, 8.0 \\n 10.0, 11.0, 12.0,'  # note \\n inserts a line break (new line)\n",
    "# print(csv_data, '\\n', type(csv_data))\n",
    "\n",
    "df = pd.read_csv(StringIO(csv_data))\n",
    "df\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can detect the missing data\n",
    "```\n",
    "print('df.info()\\n',df.info())\n",
    "print(2*'\\n')\n",
    "\n",
    "print('df.isnull()\\n',df.isnull())\n",
    "print(2*'\\n')\n",
    "\n",
    "print('df.isnull().sum()\\n',df.isnull().sum())\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"width:25%;margin-left:0;\"> \n",
    "\n",
    "### Eliminating Training Examples with Missing Values {-}\n",
    "\n",
    "- The easiest, but probably **NOT** the best, way to deal with missing data is to remove missing observations (either rows or columns)\n",
    "- In `pandas` we can use `dropna()` method\n",
    "    - `dropna(axis=1)` - remove missing features (columns)\n",
    "    - `dropna(axis=0)` - remove missing training examples (rows)\n",
    "    - https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html\n",
    "    - Most `pandas` methods have `inplace` parameter \n",
    "        - If True, do operation inplace (on our object) and return None, i.e. change directly our dataframe\n",
    "\n",
    "```\n",
    "print(df)\n",
    "print(df.dropna(axis=1)) # drop columns with missing values\n",
    "print(2*'\\n')\n",
    "print(df)\n",
    "\n",
    "\n",
    "print(df)\n",
    "print(df.dropna(axis=0))  # drop rows with missing values\n",
    "print(2*'\\n')\n",
    "print(df)\n",
    "\n",
    "\n",
    "print(df)\n",
    "print(df.dropna(how='all')) # drops rows where all columns are NaN\n",
    "print(2*'\\n')\n",
    "print(df)\n",
    "\n",
    "print(df)\n",
    "print(df.dropna(axis = 0, inplace=True)) # drop rows with missing values and with saves the changes made to df\n",
    "print(2*'\\n')\n",
    "print(df)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Imputing Missing Values {-}\n",
    "\n",
    "- Deleting missing values is not a good option when we have a small dataset\n",
    "    - Often we have limited amounts of data and need to preserve as much data as we can\n",
    "- We may employ different methods of **interpolation** to fill in missing observations\n",
    "    - Mean/median/mode (most frequent) Imputation \n",
    "    - E.g. replace missing values with the mean value of the entire feature column\n",
    "\n",
    "\n",
    "There are a number of libraries that can help deal with missing data\n",
    "1. `SimpleImputer` class from `scikit-learn` is quite useful \n",
    "    - [https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html](https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html)\n",
    "    - Can do `mean`, `median`, `most frequent` and `constant` imputation methods by setting `strategy` parameter\n",
    "    - `most frequent` method is useful for categorical feature values, e.g. colour names: red, green blue \n",
    "2. `pandas` has a built in `fillna` method\n",
    "    - [https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html)\n",
    "\n",
    "Lets interpolate missing values in our dataframe using **mean imputations** using scikit-learn\n",
    "\n",
    "```\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(StringIO(csv_data)) # --------- read in data with missing observations again ----------\n",
    "df\n",
    "\n",
    "# ---------------- sklearn method -------------------------\n",
    "\n",
    "imr = SimpleImputer(missing_values = np.nan, strategy='mean') # use mean imputation\n",
    "imr = imr.fit(df)  # .values is used to export pandas dataframe into numpy array\n",
    "\n",
    "imputed_data = imr.transform(df)\n",
    "imputed_data # notice that the data is transferred back into a NumPy array\n",
    "\n",
    "# ---------------- pandas method -------------------------\n",
    "\n",
    "df = pd.read_csv(StringIO(csv_data))  # reset df with missing values #  --------- read in data with missing observations again ----------\n",
    "df\n",
    "\n",
    "print(df.mean(axis=0)) \n",
    "print(df.fillna(df.mean(axis = 0), inplace=True))  #fill NaN with column mean values\n",
    "df\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"width:25%;margin-left:0;\"> \n",
    "\n",
    "### Scikit-learn in more depth {-}\n",
    "\n",
    "- `SimpleImputer` belongs to the **transformer** class in scikit-learn, which are used for data transformation\n",
    "- Transformers have two main methods\n",
    "    - `fit` - used to learn parameters, e.g. column means, from training data\n",
    "    - `transform` - used learned parameters to transform data\n",
    "- Any data that is to be transformed must have the same number of features as the dataset that was used to fit the transformer\n",
    "\n",
    "<img src=\"images/image1.jpg\" alt=\"Drawing\" style=\"width: 450px;\"/>\n",
    "\n",
    "\n",
    "\n",
    "- **Classifiers** that we used so far are similar to **transformers**\n",
    "    - `fit` method is used to learn parameters\n",
    "    - `predict` method is used to make predictions using trained parameters\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"images/image2.jpg\" alt=\"Drawing\" style=\"width: 450px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "# Getting Categorical Data into Shape for Use with Machine Learning Algorithms {-}\n",
    "\n",
    "- So far we have used **numerical** features data\n",
    "\n",
    "- **Categorical** data\n",
    "    - A categorical variable is a variable that can take on one of a limited, and usually fixed, number of possible values\n",
    "    - Each observation is assigned to a particular group or category on the basis of some qualitative property \n",
    "    - **Ordinal Features**: categorical values that can be ordered or sorted. E.g. shirt size: XL > L > M > S\n",
    "        - In order to use classifiers on ordinal data properly we need to convert such variables into integers, e.g. XL = 4, L = 3, M = 2, S = 1\n",
    "    - **Nominal Features**: no ordering possible. E.g. colour: {green, blue, red} \n",
    "\n",
    "\n",
    "- Create a dataset with\n",
    "    - a nominal feature (colour)\n",
    "    - an ordinal feature (size)\n",
    "    - a numerical feature (price)\n",
    "\n",
    "---\n",
    "    \n",
    "```\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame([\n",
    "    ['yellow', 'S', 8.2, 'class2'],\n",
    "    ['green', 'M', 10.1, 'class2'],\n",
    "    ['red', 'L', 13.5, 'class1'],\n",
    "    ['blue', 'XL', 15.3, 'class2']])\n",
    "\n",
    "df.columns = ['colour', 'size', 'price', 'classlabel']\n",
    "df\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping Ordinal Features {-}\n",
    "\n",
    "To map ordinal string features into integers we need to take care of the ordering of the labels  \n",
    "- Often we need to do this manually  \n",
    "- Create a new column whose values reflect ordinal feature labels mapped into integers  \n",
    "- The easiest way is to create a dictionary and map it into the original column\n",
    "\n",
    "Use `pandas` method `map`  \n",
    "- [https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.map.html](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.map.html)   \n",
    "- Used for substituting each value in a Series with another value, that may be derived from a function, a dict or a Series.\n",
    "\n",
    "Lets consider the example of shirt sizes\n",
    "```\n",
    "print(df)\n",
    "\n",
    "size_mapping = {'XL':4, 'L':3, 'M':2, 'S':1}\n",
    "print(type(size_mapping))\n",
    "\n",
    "df['size2'] = df['size'].map(size_mapping)\n",
    "\n",
    "df\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"width:35%;margin-left:0;\">   \n",
    "\n",
    "<span style='background:orange'>  **Tutorial Exercise 1** \n",
    "\n",
    "- To reverse the above mapping we can do:\n",
    "\n",
    "```\n",
    "inv_size_mapping = {v:k for k, v in size_mapping.items()}\n",
    "df['size'].map(inv_size_mapping)\n",
    "```\n",
    "\n",
    "Explain what `inv_size_mapping` does by studying the following code.\n",
    "<hr style=\"width:35%;margin-left:0;\"> \n",
    "\n",
    "```\n",
    "\n",
    "inv_size_mapping = {v:k for k, v in size_mapping.items()}\n",
    "\n",
    "print(size_mapping)\n",
    "print(size_mapping.items()) # item returns dictionary's key-value pairs\n",
    "print(type(inv_size_mapping))\n",
    "\n",
    "inv_size_mapping_2 = {} # empty dictionary\n",
    "# print(inv_size_mapping_2.items())\n",
    "\n",
    "for k, v in size_mapping.items():\n",
    "#     print(k, v)\n",
    "    inv_size_mapping_2.update({v:k})\n",
    "\n",
    "print(size_mapping)\n",
    "print('inv_size_mapping_2', inv_size_mapping_2)\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"width:35%;margin-left:0;\">   \n",
    "\n",
    "### Encoding Class Labels {-}\n",
    "\n",
    "Although most scikit-learn estimators convert class labels (target variable) to integers internally its best to provide class labels as integer arrays to avoid technical glitches\n",
    "- **Class labels are not ordinal variables**\n",
    "    - Doesn't matter which integer we assign to a particular label\n",
    "    - It is easiest to enumerate class labels starting at 0\n",
    "\n",
    "We can use `LabelEncoder` class from scikit-learn for this  \n",
    "- Use `fit_transform` method to encode labels  \n",
    "- Use `inverse_transform` to transform integer labels back to their original string representations\n",
    "    \n",
    "```\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df\n",
    "\n",
    "class_le = LabelEncoder()\n",
    "y = class_le.fit_transform(df['classlabel'].values)\n",
    "y\n",
    "\n",
    "\n",
    "y_inverse = class_le.inverse_transform(y)\n",
    "y_inverse\n",
    "\n",
    "\n",
    "\n",
    "df['classlabel2'] = y\n",
    "df['classlabel3'] = y_inverse\n",
    "df\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"width:35%;margin-left:0;\">   \n",
    "\n",
    "### One-Hot Encoding on Nominal Features {-}\n",
    "\n",
    "- We must be careful not to encode **nominal features** using integer values that represent an ordering\n",
    "    - E.g. red = 1, blue = 2, green = 3\n",
    "    - This would confuse our classifier as it will assume that somehow green > blue > red   \n",
    "   \n",
    "        \n",
    "- Instead we need to create **dummy features (variables)** for each unique value in the nominal feature column\n",
    "    - There are a number of ways to do this, e.g. use either `OneHotEncoder` scikit-learn libarary or `get_dummies` method from `pandas`\n",
    "    -[https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html)\n",
    "    \n",
    "```\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None, \"display.width\", None) # pretty printing\n",
    "df\n",
    "\n",
    "one_hot = pd.get_dummies(df[['colour']])\n",
    "print(one_hot)\n",
    "\n",
    "df = df.join(one_hot)\n",
    "df\n",
    "\n",
    "del df['colour']   # make sure we don't use both 'colour' variables as well as the dummy variables created from it\n",
    "df\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---  \n",
    "# Feature Scaling (Again) {-}\n",
    "\n",
    "Apart from **decision trees** and **random forests** most machine learning algorithms require feature scaling\n",
    "- Transforming features to the same scale ensures that weights are better optimised    \n",
    "   \n",
    "Typically there are two approaches for feature scaling:  \n",
    "1. **Standardization** which we have seen before: if $X\\sim(\\mu,\\sigma)\\Rightarrow Z=\\frac{X-\\mu}{\\sigma}\\sim(0,1)$\n",
    "    - use `StandardScaler` class from scikit-learn\n",
    "2. **Normalization** scales features to a range of $[0,1]$ interval\n",
    "    - E.g. **min-max scaling** $x_{norm}=\\frac{x-x_{min}}{x_{max} - x_{min}}$\n",
    "    - use `MinMaxScalar` class\n",
    "\n",
    "Which one is more appropriate?  \n",
    "- It really depends on data properties and should be evaluated on a case-by-case basis  \n",
    "- Standardization can be more appropriate for optimization algorithms such as gradient descent\n",
    "- In some cases normalization is more easily interpreted\n",
    "- Can always try both and see which method produces better forecasts  \n",
    "    \n",
    "Lets create some data and see how standardization and normalization compare\n",
    "\n",
    "```\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "df = pd.DataFrame(range(0, 6), columns=['X'])\n",
    "df\n",
    "\n",
    "standard_scaler = StandardScaler()\n",
    "df['X_standardized'] = standard_scaler.fit_transform(df['X'].values.reshape(-1,1))\n",
    "\n",
    "norm_scaler = MinMaxScaler()\n",
    "df['X_normalized'] = norm_scaler.fit_transform(df['X'].values.reshape(-1,1))\n",
    "\n",
    "df\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "# Selecting Meaningful Features & Overfitting (again) {-}\n",
    "\n",
    "Typically models perform better on training datasets than on test datasets. Why does this happen?  \n",
    "- Model is overfitted\n",
    "    - The model fits to the data in the training dataset too closely, including random variations in the training dataset \n",
    "    - The model then tries to predict such random variations in the test dataset but because the variations were random in the first place they don't repeat in the test data  \n",
    "    - The possibility of overfitting arises when models are too complex  \n",
    "    - Overfitted models are said to have high variance, because the predictions from overfitted models trained on different datasets vary a lot  \n",
    "    - We also say that the model does not generalize well to new data  \n",
    "- Poor performance on test data can also happen when the model has not been optimized fully, or the hyperparameters are not selected appropriately\n",
    "\n",
    "\n",
    "When is a model too complex?\n",
    "- In practice this happens means is that the model has too many parameters \n",
    "    - We are considering too many explanatory variables  \n",
    "    \n",
    "\n",
    "Possible solutions for overfitting  \n",
    "- Collect more data and train model on larger datasets  \n",
    "- Introduce a penalty for complexity via regularization  \n",
    "- Choose a simpleer model with less parameters  \n",
    "- Reduce the dimension of the data  \n",
    "\n",
    "Next we will discuss \n",
    "- Regularization (again)\n",
    "- Dimensionality reduction via feature selection\n",
    "\n",
    "Both of these techniques will lead to fewer parameters to be fitted to the data and hence reduce the amount of overfitting.\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"width:35%;margin-left:0;\"> \n",
    "\n",
    "### L1 and L2 Regularization as Penalties Against Model Complexity {-}\n",
    "\n",
    "In Week 3 we introduced L2 regularization as a method of reducing model complexity\n",
    "- Large parameter values are penalised in the cost function\n",
    "- L2 uses the values of squared parameters (this designates 2 in L2)\n",
    "\n",
    "In addition, we can also use L1 regularization which employes absolute values\n",
    "- L2: $||w||_2^2=\\sum_{j=1}^mw_j^2=w_1^2+w_2^2+\\dots+w_m^2$\n",
    "- L1: $||w||_1=\\sum_{j=1}^m|w_j|=|w_1|+|w_2|+\\dots+|w_m|$\n",
    "\n",
    "\n",
    "\n",
    "**Comparison of L1 and L2 regularizations**\n",
    "\n",
    "- Robustness: L1 is better than L2\n",
    "    - Robustness is defined as resistance to outliers in a dataset. \n",
    "    - The more able a model is to ignore extreme values in the data, the more robust it is. \n",
    "    - L1 norm is **more robust** than the L2 norm\n",
    "    - L2 norm squares values, so it increases the cost of outliers exponentially and hence tries to make large errors associated with outliers smaller\n",
    "    - L1 norm only takes the absolute value, so it considers them linearly\n",
    "- Number of Solutions: L2 has one solution which is better than L1 that has many solutions\n",
    "    - Because L2 is Euclidean distance, there is always one right answer as to how to get between two points fastest. Because L1 is taxicab distance, there are as many solutions to getting between two points as there are ways of driving between two points in Manhattan! There could be another (mirror image) path of the same length as the blue path.\n",
    "- Computational difficulty: L2 is easier to optimise than L1\n",
    "    - L2 has a closed form solution because it's using the square function which can be differentiated \n",
    "    - L1 does not have a closed form solution because it is a non-differenciable piecewise function, as it involves an absolute value. \n",
    "    - For this reason, L1 is computationally more expensive, as we can't solve it in terms of matrix math, and most rely on approximations (in the lasso case, coordinate descent).\n",
    "- Sparsity: L1 is better for feature selection than L2\n",
    "    - Sparse matrices or sparse arrays are matrices in which most of the elements are zero. \n",
    "    - By contrast, if most of the elements are nonzero, then the matrix is considered dense. \n",
    "    - While both L1 and L2 penalties shrink coefficients, L1 tends to shrink coefficients to zero whereas L2 tends to shrink coefficients evenly. \n",
    "    - L1 is therefore useful for feature selection, as we can drop any variables associated with coefficients that are estimated to be zero. \n",
    "    - This makes a model robust to potentially irrelevant features in the dataset.\n",
    "    - L2, on the other hand, is useful when we have multicollinearity.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Impact of Regularization on Logistic Regression Weights {-}\n",
    "\n",
    "We'll investigate the impact of regularisation and $C$ (inverse of regularization strength) on Logistic Regression weights \n",
    "\n",
    "- Import the wine dataset from [https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data](https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data)\n",
    "    - 178 wine examples\n",
    "    - 13 features describing their different chemical properties\n",
    " \n",
    "\n",
    "```\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# df_wine = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data')\n",
    "\n",
    "\n",
    "# df_wine.columns = ['Class label', 'Alcohol', 'Malic acid', 'Ash', 'Alcalinity of ash', 'Magnesium', 'Total phenols', \n",
    "#                    'Flavanoids', 'Nonflavanoid phenols', 'Proanthocyanins', 'Color intensity', 'Hue', 'OD280/OD315 of diluted wines',\n",
    "#                    'Proline']\n",
    "\n",
    "# df_wine.to_excel('data/wine.xls', index=False)\n",
    "\n",
    "df_wine = pd.read_excel('data/wine.xls')\n",
    "\n",
    "\n",
    "print('Class labels', np.unique(df_wine['Class label']))\n",
    "df_wine.head()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"width:35%;margin-left:0;\">   \n",
    "\n",
    "- Use `train_test_split` libarary to split the data into 70% train and 30% test datasets. \n",
    "- Stratify according to Class label\n",
    "    \n",
    "   \n",
    "    \n",
    "```\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = df_wine.iloc[:, 1:].values, df_wine.iloc[:, 0].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, stratify=y)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"width:35%;margin-left:0;\">   \n",
    "    \n",
    "- Standardize training and test datasets\n",
    "\n",
    "\n",
    "```\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "stdsc = StandardScaler()\n",
    "\n",
    "X_train_std = stdsc.fit_transform(X_train)\n",
    "X_test_std = stdsc.transform(X_test)\n",
    "```\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Normalize training and test datasets (**Normalization** scales features to a range of [0,1] interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"width:35%;margin-left:0;\">   \n",
    "\n",
    "- Fit `LogisticRegression` to the training data using L1 penalty (`penalty='l1'`, `C=1.0`, `solver='liblinear'`, `multi_class='ovr'`). \n",
    "- Compute accuracy for both training and test datasets.\n",
    "\n",
    "\n",
    "```\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# --- using standardized dataset ---\n",
    "lr = LogisticRegression(penalty='l1', C=0.1, solver='liblinear', multi_class='ovr')\n",
    "\n",
    "# Note that C=1.0 is the default. You can increase\n",
    "# or decrease it to make the regulariztion effect\n",
    "# stronger or weaker, respectively.\n",
    "\n",
    "lr.fit(X_train_std, y_train)\n",
    "\n",
    "print('Training accuracy (standardized):', lr.score(X_train_std, y_train))\n",
    "print('Testing accuracy (standardized):', lr.score(X_test_std, y_test))\n",
    "\n",
    "\n",
    "# --- using normalized dataset ---\n",
    "\n",
    "lr_nor = LogisticRegression(penalty='l1', C=0.1, solver='liblinear', multi_class='ovr')\n",
    "\n",
    "# Note that C=1.0 is the default. You can increase\n",
    "# or decrease it to make the regulariztion effect\n",
    "# stronger or weaker, respectively.\n",
    "\n",
    "lr_nor.fit(X_train_nor, y_train)\n",
    "\n",
    "print('Training accuracy (normalized):', lr_nor.score(X_train_nor, y_train))\n",
    "print('Testing accuracy (normalized):', lr_nor.score(X_test_nor, y_test))\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"width:35%;margin-left:0;\">   \n",
    "\n",
    "- Print intercepts and weight coefficients of the fitted model\n",
    "\n",
    "```\n",
    "print(lr.intercept_)\n",
    "print(lr.coef_)\n",
    "print(lr.coef_.shape)    \n",
    "\n",
    "print(lr.coef_[lr.coef_!=0])\n",
    "print(lr.coef_[lr.coef_!=0].shape)\n",
    "```\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"width:35%;margin-left:0;\">   \n",
    "    \n",
    "- Vary the regularization strength over the values [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0, 10000.0, 100000.0]\n",
    "- Plot the weight coefficients of all features for different regularization strengths\n",
    "\n",
    "\n",
    "```\n",
    "# Standardization VS Normalization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "fig = plt.figure(figsize=(8,12))\n",
    "gs = gridspec.GridSpec(2,1)\n",
    "\n",
    "# standardized data\n",
    "ax = fig.add_subplot(gs[0])\n",
    "\n",
    "colors = ['blue', 'green', 'red', 'cyan', \n",
    "          'magenta', 'yellow', 'black', \n",
    "          'pink', 'lightgreen', 'lightblue', \n",
    "          'gray', 'indigo', 'orange']\n",
    "\n",
    "weights, params = [], []\n",
    "for c in range(-4, 6):\n",
    "    lr = LogisticRegression(penalty='l1', C=10.**c, solver='liblinear', \n",
    "                            multi_class='ovr', random_state=0)\n",
    "    print(10.**c)\n",
    "    lr.fit(X_train_std, y_train)\n",
    "    weights.append(lr.coef_[1])\n",
    "    params.append(10**c)\n",
    "\n",
    "weights = np.array(weights)\n",
    "\n",
    "for column, color in zip(range(weights.shape[1]), colors):\n",
    "    ax.plot(params, weights[:, column],\n",
    "             label=df_wine.columns[column + 1],\n",
    "             color=color)\n",
    "\n",
    "plt.title(\"weight coefficients of all features for different regularization strengths (Feature Scaling - Standardization)\",\n",
    "         fontdict={'weight':'normal','size': 20})\n",
    "plt.axhline(0, color='black', linestyle='--', linewidth=3)\n",
    "plt.xlim([10**(-5), 10**5])\n",
    "plt.ylabel('weight coefficient')\n",
    "plt.xlabel('C')\n",
    "plt.xscale('log')\n",
    "plt.legend(loc='upper left')\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(1.38, 1.03),ncol=1, fancybox=True)\n",
    "\n",
    "# normalized data\n",
    "ax = fig.add_subplot(gs[1])\n",
    "\n",
    "colors = ['blue', 'green', 'red', 'cyan', \n",
    "          'magenta', 'yellow', 'black', \n",
    "          'pink', 'lightgreen', 'lightblue', \n",
    "          'gray', 'indigo', 'orange']\n",
    "\n",
    "weights, params = [], []\n",
    "for c in range(-4, 6):\n",
    "    lr_nor = LogisticRegression(penalty='l1', C=10.**c, solver='liblinear', \n",
    "                            multi_class='ovr', random_state=0)\n",
    "    print(10.**c)\n",
    "    lr_nor.fit(X_train_nor, y_train)\n",
    "    weights.append(lr_nor.coef_[1])\n",
    "    params.append(10**c)\n",
    "\n",
    "weights = np.array(weights)\n",
    "\n",
    "for column, color in zip(range(weights.shape[1]), colors):\n",
    "    ax.plot(params, weights[:, column],\n",
    "             label=df_wine.columns[column + 1],\n",
    "             color=color)\n",
    "\n",
    "plt.title(\"weight coefficients of all features for different regularization strengths (Feature Scaling - Normalization)\",\n",
    "         fontdict={'weight':'normal','size': 20})\n",
    "plt.axhline(0, color='black', linestyle='--', linewidth=3)\n",
    "plt.xlim([10**(-5), 10**5])\n",
    "plt.ylabel('weight coefficient')\n",
    "plt.xlabel('C')\n",
    "plt.xscale('log')\n",
    "plt.legend(loc='upper left')\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(1.38, 1.03),ncol=1, fancybox=True)\n",
    "\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Sequential Feature Selection {-}\n",
    "\n",
    "An alternative to L1 regularization and sparsity as a method of feature selection is **dimensionality reduction**. There are two main techniques of dimensionality reduction:\n",
    "1. **Feature Selection** - select a subset of the original features which are relevant to making forecasts\n",
    "2. **Feature Extraction** - derive information from existing features to construct a new feature subspace \n",
    "    - This is done by compressing features in to a new, smaller set of features (will study this next week)\n",
    "\n",
    "**Feature selection problem:** Out of an initial set of $d$ features choose $k$ most relevant features where $k<d$.  \n",
    "- E.g. start with $d=100$ features and reduce them to $k=25$ most relevant features.\n",
    "- Search is typically done by using **sequential** feature selection algorithms\n",
    "- Sequential selection algorithms are a type of greedy search algorithm\n",
    "\n",
    "- **Greedy Search Algorithms** - make locally optimal choices at each stage of a combinatorial search problem but generally yeild a suboptimal global solution  \n",
    "    - In the graph below, a greedy algorithm is trying to find the longest path through the graph \n",
    "        - The number inside each node represents length from previous node\n",
    "    - To do this, it selects the largest number at each step of the algorithm   \n",
    "    - With a quick visual inspection of the graph, it is clear that this algorithm will not arrive at the correct solution   \n",
    "    - What is the correct solution?     \n",
    "    \n",
    "<img src=\"images/image8.gif\" alt=\"Drawing\" style=\"width: 450px;\"/>\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In contrast **Exhaustive Search Algorithms** - evaluate all possible combinations and are guaranteed to find the optimal solution. However, an exhaustive search is often not computationally feasible.\n",
    "    - The correct solution for the longest path through the graph is 7,3,1,99. This is clear to us because we can see that no other combination of nodes will come close to a sum of 110.\n",
    "    - The greedy algorithm fails to solve this problem because it makes decisions purely based on what the best answer at the time is: at each step it did choose the largest number. \n",
    "\n",
    "\n",
    "**Sequential Backward Selection (SBS)** is a type of sequential feature selection method\n",
    "- Start by including all possible $d$ features \n",
    "- Sequentially remove features one at a time\n",
    "- In order to determine which feature to remove at each stage define the criterion function $J$, such as the accuracy of classification\n",
    "- At each step remove a features which results in the least performance loss after its removal\n",
    "\n",
    "\n",
    "**SBS algorithm**\n",
    "1. Initialize the algorithm with $k=d$\n",
    "2. Determine the feature, $x^-$ that maximizes the criterion $x^-=\\underset{x}{\\text{argmax}}J(X_k-x)$ where $x\\in X_d$\n",
    "    - Note that $J(X_k-x)<J(X_k)$ meaning that the subset $X_k-x$ has lower accuracy that $X_k$\n",
    "3. Remove the feature $x^-$ from the feature set $X_k$ resulting in $X_{k-1}=X_k-x$\n",
    "    - E.g. $J$ = accuracy, $J(x_1, x_2, x_3) = 60\\%$, $J(x_1, x_2) = 50\\%$, $J(x_1, x_3)=40\\%$, $J(x_2, x_3)=30\\%$ -> choose $J(x_1, x_2) = 50\\%$, meaning we eliminated $x_3$ in this step\n",
    "4. Terminate if $k$ is equal to the number of desired features, otherwise go to step 2.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"width:35%;margin-left:0;\">   \n",
    "\n",
    "### SBS Algorithm {-}\n",
    "\n",
    "- SBS algorithm is not implemented in scikit-learn but we can use it implement the one that comes with the textbook.\n",
    "\n",
    "```\n",
    "from sklearn.base import clone\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "class SBS():\n",
    "    def __init__(self, estimator, k_features, scoring=accuracy_score,\n",
    "                 test_size=0.25, random_state=1):\n",
    "        self.scoring = scoring\n",
    "        self.estimator = clone(estimator)\n",
    "        self.k_features = k_features\n",
    "        self.test_size = test_size\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=self.test_size,\n",
    "                             random_state=self.random_state, stratify=y)\n",
    "\n",
    "        stdsc = StandardScaler()\n",
    "        X_train = stdsc.fit_transform(X_train)\n",
    "        X_test = stdsc.transform(X_test)\n",
    "        \n",
    "\n",
    "        dim = X_train.shape[1]\n",
    "        self.indices_ = tuple(range(dim))\n",
    "        self.subsets_ = [self.indices_]\n",
    "        score = self._calc_score(X_train, y_train, \n",
    "                                 X_test, y_test, self.indices_)\n",
    "        self.scores_ = [score]\n",
    "\n",
    "        while dim > self.k_features:\n",
    "            scores = []\n",
    "            subsets = []\n",
    "\n",
    "            for p in combinations(self.indices_, r=dim - 1):\n",
    "                score = self._calc_score(X_train, y_train, \n",
    "                                         X_test, y_test, p)\n",
    "                scores.append(score)\n",
    "                subsets.append(p)\n",
    "\n",
    "            best = np.argmax(scores)\n",
    "            self.indices_ = subsets[best]\n",
    "            self.subsets_.append(self.indices_)\n",
    "            dim -= 1\n",
    "\n",
    "            self.scores_.append(scores[best])\n",
    "        self.k_score_ = self.scores_[-1]\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[:, self.indices_]\n",
    "\n",
    "    def _calc_score(self, X_train, y_train, X_test, y_test, indices):\n",
    "        self.estimator.fit(X_train[:, indices], y_train)\n",
    "        y_pred = self.estimator.predict(X_test[:, indices])\n",
    "        score = self.scoring(y_test, y_pred)\n",
    "        return score\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"width:35%;margin-left:0;\">   \n",
    "\n",
    "### Feature Selection with SBS algorithm and KNN {-}\n",
    "\n",
    "We'll use the above SBS algorithm to select a subset of predictors out of 13 features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "- Fit the SBS algorithm with KNN on wine training (standarised) data with `k_features = 1`  \n",
    "- Print optimal subsets starting from 1 to 13 features\n",
    "\n",
    "\n",
    "```\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# selecting features\n",
    "sbs = SBS(knn, k_features=1)\n",
    "\n",
    "sbs.fit(X, y)\n",
    "\n",
    "sbs.subsets_\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"width:35%;margin-left:0;\">   \n",
    "\n",
    "- Plot the classification accuracy of the KNN classifier for each subset of features\n",
    "\n",
    "```\n",
    "k_feat = [len(k) for k in sbs.subsets_]\n",
    "\n",
    "print(k_feat)\n",
    "print(sbs.scores_)\n",
    "\n",
    "plt.plot(k_feat, sbs.scores_, marker='o')\n",
    "plt.ylim([0.7, 1.02])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Number of features')\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "# plt.savefig('images/sbs_knn', dpi=300)\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"width:35%;margin-left:0;\">   \n",
    "\n",
    "- Print the smallest feature subset with the classification accuracy of 100%  \n",
    "\n",
    "```\n",
    "df_scores = pd.DataFrame(sbs.scores_, columns = ['Scores'])\n",
    "df_scores['Feature Subsets'] = sbs.subsets_\n",
    "print(df_scores)\n",
    "\n",
    "smallest_100_subset = list(df_scores['Feature Subsets'].loc[9])\n",
    "\n",
    "print(smallest_100_subset)\n",
    "\n",
    "print('features', df_wine.columns[1:]) # start from 1 since 0 is class label\n",
    "\n",
    "print(df_wine.columns[1:][smallest_100_subset])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"width:35%;margin-left:0;\">   \n",
    "\n",
    "Train KNN classifier on all features (no feature selection) and evaluate the performance on the test dataset  \n",
    "\n",
    "```\n",
    "knn.fit(X_train_std, y_train)\n",
    "print('Training accuracy:', knn.score(X_train_std, y_train))\n",
    "print('Test accuracy:', knn.score(X_test_std, y_test))  \n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"width:35%;margin-left:0;\">   \n",
    "\n",
    "Retrain the classifier on the top 4 features selected above and evaluate the performance on the test dataset \n",
    "\n",
    "```\n",
    "print(smallest_100_subset)\n",
    "knn.fit(X_train_std[:, smallest_100_subset], y_train)\n",
    "print('Training accuracy:', knn.score(X_train_std[:, smallest_100_subset], y_train))\n",
    "print('Test accuracy:', knn.score(X_test_std[:, smallest_100_subset], y_test))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "# Assessing Feature Importance with Random Forests {-}\n",
    "\n",
    "Using a random forest we can measure **feature importance** as the **averaged impurity decrease** computed from all decision trees in the forest\n",
    "- In scikit-learn access feature importance via \n",
    "    - `feature_importances` after fitting `RandomForestClassifier`\n",
    "    - `SelectFromModel` selects features based on a user-specified importance threshold\n",
    "\n",
    "A potential problem with feature importance:\n",
    "- If there is multicollinearity, i.e. features are highly correlated, it is difficult to disentangle importance\n",
    "    - One feature may rank very high while the other correlated features low (incorrectly)\n",
    "- Can check correlations between the features to see if multicollinearity is a problem in our application\n",
    "- If only interested in predictive ability then this is not a problem as we are not trying to interpret our results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"width:35%;margin-left:0;\">   \n",
    "\n",
    "<span style='background:orange'>  **Tutorial Exercise 2: Understand the code below** \n",
    "    \n",
    "a) Fit a random forest classifier to the wine data (note: Random Forest doesn't need data to be standardized)   \n",
    "b) Print feature importances  \n",
    "c) Plot feature importances  \n",
    "d) Select features with importance greater than 10%  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "\n",
    "- Fit a random forest classifier to the wine data (note: Random Forest doesn't need data to be standardized)\n",
    "\n",
    "\n",
    "```\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "feat_labels = df_wine.columns[1:]\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=500, random_state=1)\n",
    "\n",
    "forest.fit(X_train, y_train)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"width:35%;margin-left:0;\">   \n",
    "\n",
    "- Print feature importances \n",
    "\n",
    "```\n",
    "importances = forest.feature_importances_\n",
    "\n",
    "# print(importances)  # prints importances of each feature\n",
    "# print(np.argsort(importances)) # sort the index of importances from smallest to largest\n",
    "# print(np.argsort(importances)[::-1]) # reverses the index to get largest to smallest\n",
    "\n",
    "\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# print(X_train.shape)\n",
    "\n",
    "for f in range(X_train.shape[1]):\n",
    "#     print(f, indices[f])   # pick up positions from indices \n",
    "    print(f'{f+1:2})  {feat_labels[indices[f]]:40} {importances[indices[f]]:10}')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"width:35%;margin-left:0;\">   \n",
    " \n",
    "- Plot feature importances  \n",
    "\n",
    "```\n",
    "plt.title('Feature Importance')\n",
    "plt.bar(range(X_train.shape[1]), \n",
    "        importances[indices],\n",
    "        align='center')\n",
    "\n",
    "plt.xticks(range(X_train.shape[1]), \n",
    "           feat_labels[indices], rotation=90)\n",
    "plt.xlim([-1, X_train.shape[1]])\n",
    "plt.tight_layout()\n",
    "#plt.savefig('images/04_09.png', dpi=300)\n",
    "plt.show()    \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"width:35%;margin-left:0;\">   \n",
    "\n",
    "- Select features with importance greater than 10% \n",
    "\n",
    "\n",
    "```\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "sfm = SelectFromModel(forest, threshold=0.1, prefit=True)\n",
    "X_selected = sfm.transform(X_train)\n",
    "print('Number of features that meet this threshold criterion:', X_selected.shape[1])\n",
    "\n",
    "for f in range(X_selected.shape[1]):\n",
    "    print(f'{f + 1:2}) {feat_labels[indices[f]]:40} {importances[indices[f]]:10}')\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
