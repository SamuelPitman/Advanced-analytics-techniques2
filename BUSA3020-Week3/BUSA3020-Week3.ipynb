{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BUSA3020 - Advanced Analytics Techniques {-}\n",
    "## Week 3 Lecture - Classification Algorithms (Part 2) {-}\n",
    "\n",
    "\n",
    "### Unit Convenor & Lecturer {-}\n",
    "[George Milunovich](https://www.georgemilunovich.com)  \n",
    "[george.milunovich@mq.edu.au](mailto:george.milunovich@mq.edu.au)\n",
    "\n",
    "### References {-}\n",
    "\n",
    "1. Python Machine Learning 3rd Edition by Raschka & Mirjalili - Chapter 3\n",
    "2. Various open-source material\n",
    "\n",
    "### Week 3 Learning Objectives {-}\n",
    "\n",
    "- Introduce `scikit-learn` machine learning library\n",
    "    - `train` vs `test` datasets: `train_test_split` library\n",
    "    - Feature Scaling: train_test_split library\n",
    "    - Fitting `Perceptron` & Measuring Classification Accuracy via `accuracy_score`\n",
    "- Logistic Regression\n",
    "    - logit function, log-odds, logistic signoid function\n",
    "    - Predicting probabilities\n",
    "    - Predicting class labels\n",
    "    - `sklearn.linear_model.LogisticRegression` library\n",
    "- Avoiding Overfitting via Regularization\n",
    "    - Bias-Variance Tradeoff\n",
    "    - L2 Shrinkage\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Choosing a Classification Algorithm {-}\n",
    "\n",
    "When facing a practical forecasting problem the issue of which classification algorithm to use arises. \n",
    "\n",
    "In regards to this question two famous quotes come to mind:\n",
    "\n",
    "- Famous statistician G. Box once said that **All models are wrong, but some are useful**\n",
    "- Computer scientist D. Wolpert suggested that **No single classifier works best across all possible scenarios**  \n",
    "\n",
    "\n",
    "Therefore, it is a good practice to train a number of different forecasting models and compare their predictive performance\n",
    "- Choose the algorithm with produces best results in the given situation\n",
    "\n",
    "There are 5 basic steps that we will follow when `training` a `supervised` machine learning algorithm:\n",
    "\n",
    "1. Collect the data (labeled training examples)\n",
    "2. Choose a performance metric (how to measure classification performance)\n",
    "3. Choose a classifier (classification model) and optimization algorithm (how to train the model, e.g. Gradient Descent)\n",
    "4. Evaluate the performance of the model (fit the model and see how well it performs)\n",
    "5. Tune the algorithm (alterning hyperparameter values to get better performance)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Training `perceptron` with `scikit-learn` {-}\n",
    "\n",
    "In Week 2 we trained **perceptron** and **Adaline** on Iris dataset. \n",
    "\n",
    "Lets repeat what we did in Week 2 with the Iris dataset\n",
    "- Extend the dataset to all 150 observations;\n",
    "- All 3 classess of Iris;\n",
    "- We can import data from scikit-learn directly; \n",
    "- Scikit-learn has a number of popular datasets included in its library.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Importing the Dataset {-}\n",
    "\n",
    "\n",
    "```\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "# print(type(iris))\n",
    "# print(iris)\n",
    "\n",
    "print(dir(iris))\n",
    "\n",
    "# print(iris['DESCR'])\n",
    "\n",
    "print(iris['feature_names'])\n",
    "print(iris['data'][:10,:])\n",
    "\n",
    "\n",
    "X = iris['data'][:, [2, 3]] # columns indexed 2 & 3 correspond to petal length and petal width\n",
    "print(X.shape)\n",
    "\n",
    "y = iris['target']\n",
    "print(type(y), y.shape, y)\n",
    "print('Class labels:', np.unique(y)) #np.unique() finds unique values\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in our `NumPy` array $y$ we have three integer values  \n",
    "\n",
    "- 0 - Iris-setosa\n",
    "- 1 - Iris-versicolor\n",
    "- 2 - Iris-virginica\n",
    "\n",
    "--- \n",
    "\n",
    "### 2. Splitting the Dataset {-}\n",
    "\n",
    "In order to evaluate how well a trained model performs on **unseen** data, split the dataset into separate **training** and **test** datasets. \n",
    "\n",
    "We use a test dataset to avoid **overfitting** \n",
    "- Overfitting happens when the model captures \"patterns\" in the training data that do not repeat in new data\n",
    "- We say that the model fails to generalize to unseen data \n",
    "\n",
    "The image below illustrates this well. If you build a model (bed in this case) to fit every detail of your data (your sleeping position) many of the features of the model will not generalize to new data (how you sleep the following night). \n",
    "\n",
    "This happens because the model will take into account a lot of random noise (how you slept on the first night) which will not repeat in the future and hence will result in bad predictions (very uncomfortable sleep in the future). More on this in Week 5.\n",
    "\n",
    "\n",
    "<img src=\"images/overfitting.jpg\" style=\"width: 450px;\"/>\n",
    "\n",
    "![](images/overfitting.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Training and Test Datasets {-}\n",
    "\n",
    "- Lets split our data into **training** and **test** datasets\n",
    "- We will use `train_test_split` library from sklearn for this purpose\n",
    "\n",
    "\n",
    "```\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1, stratify = y)\n",
    "\n",
    "# print(X_train.shape)\n",
    "# print(y_train.shape)\n",
    "# print(X_test.shape)\n",
    "# print(y_test.shape)\n",
    "print(y_train)\n",
    "print(y_test)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the following:\n",
    "\n",
    "- `train_test_split` function automatically splits between `training` and `test` dataset\n",
    "- the size of the test dataset is 20% of all available observations, and the size of the training set is the remaining 80%\n",
    "- `train_test_split` also randomizes the dataset before spliting it, this avoids for instance having all 0's and 1's in the training set and 2's in the test set\n",
    "- `random_state = 1` sets a value for the random number generator which shuffles the dataset prior to splitting. This allows us to replicate our results (data always shuffled in the same way) \n",
    "- in addition to shuffling the dataset note that we also employ `stratify = y` option in `train_test_split()`. This ensures that the training and test datasets have the same proportions of class lables as the input dataset. \n",
    "\n",
    "Lets check counts and proportions of each class label in the 3 datasets using `bincount` function from NumPy\n",
    "```\n",
    "print(y_train)\n",
    "print('Train Dataset', 'counts', np.bincount(y_train), 'proportions', np.bincount(y_train)/len(y_train))\n",
    "print('Test Dataset', 'counts', np.bincount(y_test), 'proportions', np.bincount(y_test)/len(y_test))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3. Features Scaling {-}\n",
    "\n",
    "In Week 2 we discussed how standardization of features can help optimization algorithms train classifiers. \n",
    "\n",
    "- `scikit-learn` contains `preprocessing` module which contains a number of classes used for standardization\n",
    "- For now we will use `StandardScalar` class \n",
    "- Scale the data by doing the following transformation $X\\sim(\\mu, \\sigma) \\rightarrow Z(0, 1)$\n",
    "\n",
    "Note that we use `training` dataset to estimate the parameters $\\mu \\text{ and } \\sigma$ which are then used to standardize both the `training` and `test` datasets. \n",
    "- This prevents cheating and increasing forecast accuracy by assuming how the observations from the `test` dataset are distributed.\n",
    "\n",
    "```\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "np.set_printoptions(precision=3, suppress = True) # pretty printing\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "sc.fit(X_train)\n",
    "\n",
    "# print(dir(sc))\n",
    "# print(sc.mean_, sc.scale_)\n",
    "\n",
    "\n",
    "X_train_scaled = sc.transform(X_train)\n",
    "print('means:', X_train.mean(axis=0), X_train_scaled.mean(axis=0))\n",
    "print('sigmas', X_train.std(axis=0), X_train_scaled.std(axis=0))\n",
    "\n",
    "X_test_scaled = sc.transform(X_test)\n",
    "print('means:', X_test.mean(axis=0), X_test_scaled.mean(axis=0))\n",
    "print('sigmas', X_test.std(axis=0), X_test_scaled.std(axis=0))\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 4. Training the Classifier {-}\n",
    "\n",
    "Note that our dataset consists of three classes: \n",
    "1. setosa\n",
    "2. versicolor\n",
    "3. virginica \n",
    "\n",
    "Most scikit-learn clasifiers support **multiclass classification** by default via the **one-vs.rest (OvR)**/**one-vs-all (OvA)** method.\n",
    "\n",
    "Let's implement `scikit-learn` library `Perceptron`\n",
    "- See documentation [https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Perceptron.html](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Perceptron.html)\n",
    "- To initialize it we set `eta0` which is the learning rate $(\\eta)$, and `random_state` which is used in order to be able to reproduce the results \n",
    "- `random-state` is used to shuffle the data after each epoch\n",
    "\n",
    "```\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "ppn = Perceptron(eta0=0.1, random_state=1)\n",
    "ppn.fit(X_train_scaled, y_train)\n",
    "\n",
    "print('--- Estimated Weights ---')\n",
    "print('intercept:\\n', ppn.intercept_)\n",
    "print('coefficients:\\n', ppn.coef_)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Why are there so many estimated weights (coefficients)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 5. Producing Forecasts and Measuring Accuracy {-}\n",
    "\n",
    "Now that we've trained `scikit-learn` Perceptron we can employ it to classify our `test` dataset.\n",
    "\n",
    "For each prediction $\\hat{y}^{(i)}$ we could either have\n",
    "- correct classification if $\\hat{y}^{(i)} = y^{(i)}$\n",
    "- misclassification if $\\hat{y}^{(i)} \\ne y^{(i)}$\n",
    "\n",
    "To compute **misclassification error** we can sum all misclassified examples and divide by the number of examples classified. \n",
    "\n",
    "Lets say that we classify $k$ examples then \n",
    "\n",
    "- $\\text{error} = \\frac{1}{k}\\sum_{j=1}^k1_{\\hat{y}^{(j)} \\ne y^{(j)}}$\n",
    "\n",
    "**Classification accuracy** then becomes:\n",
    "\n",
    "- $\\text{accuracy}=1-\\text{error}$\n",
    "\n",
    "---\n",
    "\n",
    "```\n",
    "\n",
    "y_train_pred = ppn.predict(X_train_scaled)\n",
    "\n",
    "# print('Predictions:', y_train_pred)\n",
    "# print('True Labels:', y_train)\n",
    "\n",
    "print('Number of incorrectly classified in training set:', (y_train != y_train_pred).sum())\n",
    "\n",
    "error_train = (y_train != y_train_pred).sum()/len(y_train)\n",
    "\n",
    "print(f'Misclassification Error: {error_train:.3f}')\n",
    "print(f'Accuracy: {1 - error_train:.3f}')\n",
    "\n",
    "print(40*'=')\n",
    "\n",
    "y_test_pred = ppn.predict(X_test_scaled)\n",
    "print('Number of incorrectly classified in test set:', (y_test != y_test_pred).sum())\n",
    "error_test = (y_test != y_test_pred).sum()/len(y_test)\n",
    "\n",
    "print(f'Misclassification Error: {error_test:.3f}')\n",
    "print(f'Accuracy: {1 - error_test:.3f}')\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "`scikit-learn` provides a numer of different **performance metrics** in its `metrics` module\n",
    "- **classification accuracy** is one of such performance measues \n",
    "- Misclassification error $=1-\\text{accuracy}$.\n",
    "\n",
    "```\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(f'Accuracy = {accuracy_score(y_test, y_test_pred):.3f}')\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "We can also use the `score` method which is function built into most `sklearn` classifiers\n",
    "- Its a shortcut to first producing the forecast via `predict` and then computing the accuracy via `accuracy_score` \n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "print(f'Accuracy = {ppn.score(X_test_scaled, y_test):.3f}')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Plotting Decision Regions {-}\n",
    "\n",
    "\n",
    "We can re-use the code from Week 2 to plot the **decision regions**\n",
    "- visualise how well the model separates the classes\n",
    "- copy and paste the `plot_decision_regions` function from Week 2\n",
    "- function is modified to depict test dataset examples\n",
    "\n",
    "\n",
    "```\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# # To check recent matplotlib compatibility\n",
    "# import matplotlib\n",
    "# from distutils.version import LooseVersion\n",
    "\n",
    "\n",
    "def plot_decision_regions(X, y, classifier, test_idx=None, resolution=0.02):\n",
    "\n",
    "    # setup marker generator and color map\n",
    "    markers = ('o', 's', '^', 'v', '<')\n",
    "    colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')\n",
    "    cmap = ListedColormap(colors[:len(np.unique(y))])\n",
    "\n",
    "    # plot the decision surface\n",
    "    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),\n",
    "                           np.arange(x2_min, x2_max, resolution))\n",
    "    lab = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n",
    "    lab = lab.reshape(xx1.shape)\n",
    "    plt.contourf(xx1, xx2, lab, alpha=0.3, cmap=cmap)\n",
    "    plt.xlim(xx1.min(), xx1.max())\n",
    "    plt.ylim(xx2.min(), xx2.max())\n",
    "\n",
    "    # plot class examples\n",
    "    for idx, cl in enumerate(np.unique(y)):\n",
    "        plt.scatter(x=X[y == cl, 0], \n",
    "                    y=X[y == cl, 1],\n",
    "                    alpha=0.8, \n",
    "                    c=colors[idx],\n",
    "                    marker=markers[idx], \n",
    "                    label=f'Class {cl}', \n",
    "                    edgecolor='black')\n",
    "\n",
    "    # highlight test examples\n",
    "    if test_idx:\n",
    "        # plot all examples\n",
    "        X_test, y_test = X[test_idx, :], y[test_idx]\n",
    "\n",
    "        plt.scatter(X_test[:, 0],\n",
    "                    X_test[:, 1],\n",
    "                    c='none',\n",
    "                    edgecolor='black',\n",
    "                    alpha=1.0,\n",
    "                    linewidth=1,\n",
    "                    marker='o',\n",
    "                    s=100, \n",
    "                    label='Test set')        \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "- Visualisation code is now in computer memory\n",
    "- Next we use it\n",
    "- Note: although the model has been fitted on `training` dataset, we will use it to classify the entire dataset\n",
    "\n",
    "\n",
    "```\n",
    "print(X_train_scaled.shape)\n",
    "print(X_test_scaled.shape)\n",
    "\n",
    "X_combined_scaled = np.vstack((X_train_scaled, X_test_scaled))\n",
    "# print(X_combined_scaled.shape)\n",
    "\n",
    "# print(y_train.shape)\n",
    "# print(y_test.shape)\n",
    "y_combined = np.hstack((y_train, y_test))\n",
    "# print(y_combined.shape)\n",
    "\n",
    "plot_decision_regions(X=X_combined_scaled, y=y_combined, classifier=ppn)\n",
    "\n",
    "plt.xlabel('patel length [standardized]')\n",
    "plt.ylabel('patel width [standardized]')\n",
    "plt.legend(loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**: the three flower classes cannot be perfectly separated by a linear decision boundary.   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Modelling Class Probabilities via Logistic Regression {-}\n",
    "\n",
    "The main problem with Perceptron is that it does not converge to fixed values for weights if classes are not perfectly linearly separable, see e.g. previous image. \n",
    "- In Week 2 we saw that the weights will keep getting updated as long as there is a single misclassification \n",
    "- There are other linear classifiers which will converge to a cost minimum even if he classes are not linearly separable\n",
    "\n",
    "**Logistic regression** is one of the most widely used classification models in the industry\n",
    "- Basic logistic regression is used for binary classification\n",
    "- Multiclass classification can be done either via *OvR* or multinomial logistic regression (softmax regression) \n",
    "    - see [https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Theory behind Logistic Regression {-}\n",
    "\n",
    "Let us introduce the following:\n",
    "- There are only two events, $A$ and $B$, e.g. $A=$pass BUSA3020, $B=$fail BUSA3020\n",
    "- variable $y=1$ if $A$ occurs and $y=0$ if $B$ occurs\n",
    "- $p$ - probability of event $A$, e.g. $p = 60\\%=0.6$\n",
    "- $P(y=1)=p\\Rightarrow P(y=0)=1-P(y=1)=1-p$\n",
    "- **odds** - odds in favour of event $A$ (or equivalently $y=1$), $\\text{odds}=\\frac{p}{1-p}$\n",
    "    - e.g. odds=$\\frac{0.6}{0.4}=\\frac{3}{2}$ this can be said \"3 to 2 odds\" meaning that out of 5 students, odds are that 3 students will pass (events $A$) and 2 students will fail (event $B$)\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "Having the above definitions we can now introduce the **logit function** $\\text{logit}(p)=\\text{logit(P[y=1])}=\\text{ln}(\\frac{p}{1-p})$   \n",
    "where **ln** is the natural logarithm function. Note the following:\n",
    "\n",
    "- $(\\frac{p}{1-p})\\in[0,\\infty)$ \n",
    "- $\\text{logit}(p)=\\text{ln}(\\frac{p}{1-p})\\in(-\\infty, \\infty)$ \n",
    "\n",
    "```\n",
    "p = np.arange(0.00000001, 1, 0.049999999)\n",
    "print('p', p)\n",
    "odds = p / (1-p)\n",
    "print('odds', odds)\n",
    "logit = np.log(odds)\n",
    "print('logit', logit)\n",
    "\n",
    "plt.plot(logit)\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "\n",
    "We are familiar with the notion of conditional probability $P(y=1|x)$ which gives the probability that $y=1$ given that $x$ takes on some value\n",
    "- e.g. probability that a student will pass BUSA3020 $(y=1)$ given that the student has studied 4 hours per day $(x=4)$, i.e.  $P(y=1|x=4)$\n",
    "- this is clearly different from $P(y=1)$\n",
    "\n",
    "Similary we can define the **log-odds** using the logit function $\\text{logit}\\left(P(y=1|x)\\right)=\\text{ln}\\left(\\frac{P(y=1|x)}{1-P(y=1|x)}\\right)$ \n",
    "\n",
    "Now lets say that $\\text{logit}\\left(P(y=1|x)\\right)$ can in fact be represented as a linear function of the features - $x$ variables:\n",
    "\n",
    "$z=\\text{logit}\\left(P(y=1|x)\\right)=w_0x_0+w_1x_1+\\dots+w_mx_m=\\sum_{i=0}^{m}w_ix_i=\\mathbf{w}^{T}\\mathbf{x}$\n",
    "\n",
    "To be able to predict (get the probability) that a certain example belongs to a particular class we need the **inverse** of the logit function\n",
    "- The inverse of the logistic function is called the **logistic sigmoid function** or just **sigmoid function** or **logistic tranformation**\n",
    "- $P(y=1|x)=\\phi(z)=\\frac{1}{1+e^{-z}}$\n",
    "\n",
    "where $z$ is the net input given by <span style='background:lightblue'> $z=\\text{logit}\\left(P(y=1|x)\\right)=w_0x_0+w_1x_1+\\dots+w_mx_m$ </span> in this case.\n",
    "\n",
    "Lets see what $\\phi(z)$ looks like:\n",
    "\n",
    "```\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1.0 + np.exp(-z))\n",
    "\n",
    "z = np.arange(-7, 7.1, 0.1)\n",
    "print(z, type(z))\n",
    "\n",
    "phi_z = sigmoid(z)\n",
    "print(phi_z)\n",
    "\n",
    "plt.plot(z, phi_z)\n",
    "plt.xlabel('z')\n",
    "plt.axvline(0.0, color='gray')\n",
    "plt.ylabel('$\\phi(z)$')\n",
    "plt.yticks([0.0, 0.5, 1.0])\n",
    "ax = plt.gca()\n",
    "ax.yaxis.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe the following:\n",
    "- The graph resembles an S-shaped curve\n",
    "- $z\\rightarrow\\infty\\Rightarrow\\phi(z)\\rightarrow1$\n",
    "- $z\\rightarrow-\\infty\\Rightarrow\\phi(z)\\rightarrow0$\n",
    "- Since $\\phi(z)\\in[0,1]$ it can be used to model probabilities. For example we can use it in:\n",
    "    - Credit card fraud detection: predict whether a person will default and also the probability of default\n",
    "    - Weather forecasting: predict if it will rain and the chance of rain\n",
    "    - Medical applications: decide if a patient has a disease and the chance of the disease given the symptoms\n",
    "    - Etc.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Consider the comparison of **Logistic Regression** with **Perceptron** and **Adaline**:\n",
    "\n",
    "<hr style=\"width:15%;margin-left:0;\">\n",
    "\n",
    "**Perceptron**\n",
    "    \n",
    "$z=w_0 + w_1x_1 +  w_2x_2=\\sum_{j=0}^{3}w_jx_j=\\mathbf{w}^{T}\\mathbf{x}$\n",
    "\n",
    "$\\phi(z)=\\left\\{ \n",
    "\\begin{array}{cc}\n",
    "1 & \\text{if } z \\ge 0 \\hfill \\\\ \n",
    "0 & \\text{otherwise,}\n",
    "\\end{array}\n",
    "\\right.$\n",
    "\n",
    "$\\hat{y}=\\phi(z)$\n",
    "\n",
    "<hr style=\"width:15%;margin-left:0;\">\n",
    "\n",
    "**Adaline**\n",
    "\n",
    "$z=w_0 + w_1x_1 +  w_2x_2=\\sum_{j=0}^{3}w_jx_j=\\mathbf{w}^{T}\\mathbf{x}$\n",
    "\n",
    "$\\phi(z)=\\phi(w^{T}x)=w^{T}x$\n",
    "\n",
    "$\\hat{y}=\\left\\{ \n",
    "\\begin{array}{cc}\n",
    "1 & \\text{if } \\phi(z) \\ge 0 \\hfill \\\\ \n",
    "0 & \\text{otherwise}\n",
    "\\end{array}\n",
    "\\right.$\n",
    "\n",
    "<hr style=\"width:15%;margin-left:0;\">\n",
    "\n",
    "**Logistic Regression**\n",
    "\n",
    "$z=w_0 + w_1x_1 +  w_2x_2=\\sum_{j=0}^{3}w_jx_j=\\mathbf{w}^{T}\\mathbf{x}$\n",
    "\n",
    "$\\phi(z)=\\frac{1}{1+e^{-z}}$\n",
    "\n",
    "The sigmoid function is interpreted as the *conditional probability* of a particular example belonging to class 1:\n",
    "\n",
    "- $P(y=1|x)=\\phi(z)$\n",
    "- $P(y=0|x)= 1- P(y=1|x)$\n",
    "\n",
    "E.g. $\\phi(z)=0.8$ means that the probability that the flower is Iris-Versicolor is 80% and the prob that it is Iris-Setosa is 20%.\n",
    "\n",
    "$\\hat{y}=\\left\\{ \n",
    "\\begin{array}{cc}\n",
    "1 & \\text{if } \\phi(z) \\ge 0.5 \\hfill \\\\ \n",
    "0 & \\text{otherwise}\n",
    "\\end{array}\n",
    "\\right.$\n",
    "\n",
    "Equivallently we can use\n",
    "\n",
    "$\\hat{y}=\\left\\{ \n",
    "\\begin{array}{cc}\n",
    "1 & \\text{if } z \\ge 0 \\hfill \\\\ \n",
    "0 & \\text{otherwise}\n",
    "\\end{array}\n",
    "\\right.$\n",
    "\n",
    "\n",
    "<img src=\"images/image1.jpg\" alt=\"Drawing\" style=\"width: 450px;\"/>\n",
    "\n",
    "![](images/image1.jpg)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning the Weights of the Logistic Cost Function {-}\n",
    "\n",
    "The estimating (fitting) of the parameters in the Logistic Regression model is based on the principle of **Maximum Likelihood Estimation (MLE)**. MLE is a method of estimating the parameters of a probability distribution by maximizing a **likelihood function**, so that under the assumed statistical model the observed data is most probable. \n",
    "\n",
    "The point in the parameter space that maximizes the likelihood function is called the **maximum likelihood estimate**. The logic of maximum likelihood is both intuitive and flexible, and as such the method has become a dominant means of statistical inference. For more details on MLE see [https://en.wikipedia.org/wiki/Maximum_likelihood_estimation](https://en.wikipedia.org/wiki/Maximum_likelihood_estimation).\n",
    "\n",
    "- Maximum Likelihood Estimation is beyond the scope of this unit\n",
    "- If interested in further details refer to the above URL as well as the textbook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Training a Logistic Regression Model with `scikit-learn` {-}\n",
    "\n",
    "- `sklearn.linear_model.LogisticRegression` class\n",
    "    - [https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n",
    "- As mentioned above `scikit-learn` implements multiclass classification by default via two methods OvR or multinomial\n",
    "    - `multi_class='ovr`\n",
    "    - `multi_class='multinomial'` - recommended for multually exclusive classes\n",
    "    \n",
    "```\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(C=100.0, random_state=1, solver='lbfgs', multi_class='ovr')\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "plot_decision_regions(X_combined_scaled, y_combined, classifier=lr, test_idx=range(105, 150))\n",
    "plt.xlabel('patel length [standardized]')\n",
    "plt.ylabel('patel width [standardized]')\n",
    "plt.legend(loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see there are a number of options we need to provide to initialize `LogisticRegression`\n",
    "\n",
    "- Optimization algorithm \n",
    "- We use Limited-memory BFGS here using `solver='lbfgs'`. This is a more sophisticated optimization algorithm based on the second derivative (Hessian matrix). See [https://en.wikipedia.org/wiki/Limited-memory_BFGS](https://en.wikipedia.org/wiki/Limited-memory_BFGS)\n",
    "- `C` parameter refers to 'Inverse of regularization strength' - see below\n",
    "\n",
    "\n",
    "Lets make the following forecasts for the first 4 rows of the test set:\n",
    "- forecast the probability that each of the four examples belongs in each of the three categories using `predict_proba()`\n",
    "- forecast which category each of the four examples will belong to using `predict()`\n",
    "\n",
    "```\n",
    "print(X_test_scaled[:4, :])\n",
    "print(2*'\\n')\n",
    "\n",
    "# print(lr.predict_proba(X_test_scaled[:4, :]))\n",
    "print(np.around(lr.predict_proba(X_test_scaled[:4, :]), 3)) # round off to 3 decimal places\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given our classes \n",
    "\n",
    "- 0 - Iris-setosa\n",
    "- 1 - Iris-versicolor\n",
    "- 2 - Iris-virginica\n",
    "\n",
    "we see that the first flower has about 57% chance of being Iris-virginica, While the second flower has 77% chance of being an Iris-setosa. These are conditional probabilities of each flower belonging to a class based on their petal characteristics. \n",
    "\n",
    "To get predicted class labels $\\hat{y}^{(i)}\\in{0, 1, 2}$ we just choose the class which corresponds with the **highest** probability\n",
    "\n",
    "```\n",
    "print(lr.predict_proba(X_test_scaled[:4, :]).argmax(axis=1))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simpler way to do the same thing is \n",
    "```\n",
    "print(lr.predict(X_test_scaled[:4, :]))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: When forecasting from a single example (single row slice) which has only one dimension we need to first create a 2-D array which `scikit-learn` expects. Do this using `reshape` command\n",
    "\n",
    "```\n",
    "print(X_test_scaled[0, :])\n",
    "print(X_test_scaled[0, :].shape)\n",
    "print(X_test_scaled[0:2, :].shape)\n",
    "\n",
    "print(X_test_scaled[0, :].reshape(1, -1))\n",
    "print(X_test_scaled[0, :].reshape(1, -1).shape)\n",
    "\n",
    "\n",
    "\n",
    "# print(lr.predict(X_test_scaled[0, :]))\n",
    "print(lr.predict(X_test_scaled[0, :].reshape(1, -1)))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Avoiding Overfiting via Regularization {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Overfitting** - when a model performs well on training data but does not generalize well to unseen data (generates bad forecast on new data)\n",
    "\n",
    "**Underfitting** - when a model is too simple to capture the patterns found in training data \n",
    "\n",
    "**Bias-Variance Tradeoff**\n",
    "\n",
    "- **High Variance**\n",
    "    - Overfitting typically happens when the model is too complex and has too many parameters -> likely to pick up random noise\n",
    "    - Imagine training an overly complex model on multiple datasets -> each time model will 'learn' what appears to be a different pattern in each dataset, but is in fact noise which does not repeat again\n",
    "    - When we forecast the same example/observation from such multiple models there is likely to be high **variability** in the prediction across the trained models because each model is trained to predict based on the noise that it remembered\n",
    "    - We say that such a model has **high variance** because the predictions are highly variables from one version of the model to the next\n",
    "\n",
    "\n",
    "- **High Bias**\n",
    "    - Bias measures how different the predictions are from the correct values if we rebuild the model multiple times on different training data\n",
    "    - It is a measure of systematic error which is not due to randomness\n",
    "    - Models which are too simple (underfitted) will not be able to predict test data correctly and will be far off from true value -> will have **high bias**\n",
    "    \n",
    "    \n",
    "\n",
    "<img src=\"images/image2.jpg\" alt=\"Drawing\" style=\"width: 450px;\"/>\n",
    "\n",
    "![](images/image2.jpg)\n",
    "    \n",
    "**Regularization** is the process of adding information in order to prevent overfitting and reach a good bias-variance tradeoff.\n",
    "- In ML regularization works by adding information to penalize large parameter (weight) values\n",
    "- Regularization helps with collinearity (high correlation among features)\n",
    "- For regularization to work properly all features must be on comparable scale -> **feature scaling** is important\n",
    "- **L2 regularization** (L2 shrinkage) most common, where $\\lambda$ is called the **regularization parameter**\n",
    "    - By increasing $\\lambda$ we increase regularization strength, penalizing more large parameter values and hence obtaining more parameters closer to zero-> less overfit\n",
    "    - in `LogisticRegression` $C=\\frac{1}{\\lambda}$ -> small $C$ = large $\\lambda$ -> will reduce the magnitude of the estimated parameters\n",
    "\n",
    "Regularization term $\\frac{\\lambda}{2}||w||^2=\\frac{\\lambda}{2}\\sum_{j=1}^{m}w_j^2$ is often added to the Logistic Regression cost function, which will shrink (make smaller) estimated parameters (weights)\n",
    "\n",
    "$J(w)=\\sum_{i=1}^n\\left[-y^{(i)}\\text{ln}\\left(\\phi(z^{(i)})\\right)-\\left(1-y^{(i)}\\right)\\text{ln}\\left(1-\\phi(z^{(i)})\\right)\\right] + \\frac{\\lambda}{2}||w||^2$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
